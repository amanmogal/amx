.. _openvino_docs_deployment_guide_introduction_zh_CN:

OpenVINO™ 部署简介
====================

构建符合 OpenVINO™ 和您的要求的模型后，即可选择通过以下几种方法部署该模型与应用：

* :doc:`在本地部署应用 <deployment_guide_zh_CN.rst>`。
* `通过 OpenVINO™ 模型服务器部署模型 <https://docs.openvino.ai/2022.2/ovms_what_is_openvino_model_server.html>`_。
* :doc:`部署应用以便集成 TensorFlow 框架与 OpenVINO <openvino_ecosystem_ovtf_zh_CN.rst>`。


.. note:: 
   请注意，:ref:`在 OpenVINO™ 运行时运行推理 <openvino_intro_zh_CN.rst>` 是最基本的部署形式。在继续之前，请确保了解如何创建正确的推理配置。