Model name,Throughput: (tokens/sec. 2nd token),1st token latency (msec),Max_RSS_memory used. (MB),Input tokens,Output tokens,Model Precision,Beam,Batch size,Framework
falcon-7b-instruct,0,4551,Data is coming.,1049,128,INT4,1,1,PT
vicuna-7b-v1.5,0,3982,Data is coming.,1024,128,INT4,1,1,PT
opt-2.7b,20.23,2756,Data is coming.,937,128,INT4,1,1,PT
phi-3-mini-4k-instruct,19.90,2775,Data is coming.,1062,128,INT4,1,1,PT
orca-mini-3b,19.22,2966,Data is coming.,1024,128,INT4,1,1,PT
phi-2,17.82,2161,Data is coming.,1024,128,INT4,1,1,PT
stable-zephyr-3b-dpo,16.96,1791,Data is coming.,946,128,INT4,1,1,PT
chatglm3-6b,16.49,3569,Data is coming.,1024,128,INT4,1,1,PT
dolly-v2-3b,15.84,6890,Data is coming.,1024,128,INT4,1,1,PT
stablelm-3b-4e1t,15.69,2050,Data is coming.,1024,128,INT4,1,1,PT
red-pajama-incite-chat-3b-v1,14.81,6582,Data is coming.,1020,128,INT4,1,1,PT
codegen25-7b,13.34,3982,Data is coming.,1024,128,INT4,1,1,PT
gpt-j-6b,13.17,7212,Data is coming.,1024,128,INT4,1,1,PT
stablelm-7b,12.82,6339,Data is coming.,1020,128,INT4,1,1,PT
llama-3-8b,12.76,4355,Data is coming.,1024,128,INT4,1,1,PT
llama-2-7b-chat,12.25,4205,Data is coming.,1024,128,INT4,1,1,PT
llama-7b,11.74,4314,Data is coming.,1024,128,INT4,1,1,PT
mistral-7b-v0.1,10.53,4462,Data is coming.,1007,128,INT4,1,1,PT
zephyr-7b-beta,10.48,4499,Data is coming.,1024,128,INT4,1,1,PT
qwen1.5-7b-chat,9.88,4318,Data is coming.,1024,128,INT4,1,1,PT
baichuan2-7b-chat,9.81,4667,Data is coming.,1024,128,INT4,1,1,PT
qwen-7b-chat,8.95,5141,Data is coming.,1024,128,INT4,1,1,PT