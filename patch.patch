diff --git a/inference-engine/tests/functional/plugin/cpu/shared_tests_instances/behavior/set_preprocess.cpp b/inference-engine/tests/functional/plugin/cpu/shared_tests_instances/behavior/set_preprocess.cpp
index 706db708..24157862 100644
--- a/inference-engine/tests/functional/plugin/cpu/shared_tests_instances/behavior/set_preprocess.cpp
+++ b/inference-engine/tests/functional/plugin/cpu/shared_tests_instances/behavior/set_preprocess.cpp
@@ -2,13 +2,17 @@
 // SPDX-License-Identifier: Apache-2.0
 //
 
+#include <common_test_utils/behavior_test_utils.hpp>
 #include "multi-device/multi_device_config.hpp"
 
-#include "common_test_utils/behavior_test_utils.hpp"
+#include "behavior/set_preprocess.hpp"
+//#include "behavior/"
 
-using namespace BehaviorTestsUtils;
+//using namespace BehaviorTestsUtils;
 
 namespace {
+    using PreprocessBehTest = BehaviorTestsUtils::BehaviorTestsBasic;
+
     const std::vector<InferenceEngine::Precision> netPrecisions = {
             InferenceEngine::Precision::FP32,
             InferenceEngine::Precision::FP16
diff --git a/inference-engine/tests/functional/plugin/shared/include/behavior/set_preprocess.hpp b/inference-engine/tests/functional/plugin/shared/include/behavior/set_preprocess.hpp
index 4c3402d6..3a712565 100644
--- a/inference-engine/tests/functional/plugin/shared/include/behavior/set_preprocess.hpp
+++ b/inference-engine/tests/functional/plugin/shared/include/behavior/set_preprocess.hpp
@@ -2,33 +2,68 @@
 // SPDX-License-Identifier: Apache-2.0
 //
 
-#pragma once
-
-#include <tuple>
 #include <vector>
-#include <string>
-#include <memory>
-#include "ie_extension.h"
-#include <condition_variable>
+
+#include <ie_core.hpp>
+#include "common_test_utils/test_assertions.hpp"
+#include "common_test_utils/common_utils.hpp"
+#include "functional_test_utils/plugin_cache.hpp"
 #include "functional_test_utils/layer_test_utils.hpp"
-#include "ngraph_functions/utils/ngraph_helpers.hpp"
-#include "ngraph_functions/builders.hpp"
-
-namespace LayerTestsDefinitions {
-    typedef std::tuple<
-            InferenceEngine::Precision,         // Network precision
-            std::string,                        // Device name
-            std::map<std::string, std::string>  // Config
-    > PreProcessParams;
-
-class PreProcessTests : public testing::WithParamInterface<PreProcessParams>,
-        public LayerTestsUtils::LayerTestsCommon {
-public:
-    static std::string getTestCaseName(testing::TestParamInfo<PreProcessParams> obj);
-
-protected:
-    void SetUp() override;
-    void TearDown() override;
-};
-
-}  // namespace LayerTestsDefinitions
\ No newline at end of file
+#include "functional_test_utils/blob_utils.hpp"
+#include "ie_preprocess.hpp"
+#include "common_test_utils/behavior_test_utils.hpp"
+
+using PreprocessBehTest = BehaviorTestsUtils::BehaviorTestsBasic;
+
+TEST_P(PreprocessBehTest, SetPreProcessToInputInfo) {
+    // Skip test according to plugin specific disabledTestPatterns() (if any)
+    SKIP_IF_CURRENT_TEST_IS_DISABLED()
+    // Create CNNNetwork from ngrpah::Function
+    InferenceEngine::CNNNetwork cnnNet(function);
+
+    auto &preProcess = cnnNet.getInputsInfo().begin()->second->getPreProcess();
+    preProcess.setResizeAlgorithm(InferenceEngine::ResizeAlgorithm::RESIZE_BILINEAR);
+
+    // Get Core from cache
+    auto ie = PluginCache::get().ie();
+    // Load CNNNetwork to target plugins
+    auto execNet = ie->LoadNetwork(cnnNet, targetDevice, configuration);
+    // Create InferRequest
+    auto req = execNet.CreateInferRequest();
+    {
+        InferenceEngine::ConstInputsDataMap inputsMap = execNet.GetInputsInfo();
+        const auto &name = inputsMap.begin()->second->name();
+        const InferenceEngine::PreProcessInfo *info = &req.GetPreProcess(name.c_str());
+        ASSERT_EQ(info->getResizeAlgorithm(), InferenceEngine::ResizeAlgorithm::RESIZE_BILINEAR);
+        ASSERT_PREPROCESS_INFO_EQ(preProcess, *info);
+    }
+    function.reset();
+}
+
+TEST_P(PreprocessBehTest, SetPreProcessToInferRequest) {
+    // Skip test according to plugin specific disabledTestPatterns() (if any)
+    SKIP_IF_CURRENT_TEST_IS_DISABLED()
+    // Create CNNNetwork from ngrpah::Function
+    InferenceEngine::CNNNetwork cnnNet(function);
+
+    auto &preProcess = cnnNet.getInputsInfo().begin()->second->getPreProcess();
+    preProcess.setResizeAlgorithm(InferenceEngine::ResizeAlgorithm::RESIZE_BILINEAR);
+
+    // Get Core from cache
+    auto ie = PluginCache::get().ie();
+    // Load CNNNetwork to target plugins
+    auto execNet = ie->LoadNetwork(cnnNet, targetDevice, configuration);
+    // Create InferRequest
+    auto req = execNet.CreateInferRequest();
+    InferenceEngine::ConstInputsDataMap inputsMap = execNet.GetInputsInfo();
+    const auto &name = inputsMap.begin()->second->name();
+    auto inputBlob = FuncTestUtils::createAndFillBlob(
+            cnnNet.getInputsInfo().begin()->second->getTensorDesc());
+    req.SetBlob(cnnNet.getInputsInfo().begin()->first, inputBlob);
+    {
+        const InferenceEngine::PreProcessInfo *info = &req.GetPreProcess(name.c_str());
+        ASSERT_EQ(cnnNet.getInputsInfo().begin()->second->getPreProcess().getResizeAlgorithm(),
+                  info->getResizeAlgorithm());
+    }
+    function.reset();
+}
diff --git a/inference-engine/tests/functional/plugin/shared/src/behavior/set_preprocess.cpp b/inference-engine/tests/functional/plugin/shared/src/behavior/set_preprocess.cpp
deleted file mode 100644
index 5af6bad9..00000000
--- a/inference-engine/tests/functional/plugin/shared/src/behavior/set_preprocess.cpp
+++ /dev/null
@@ -1,73 +0,0 @@
-// Copyright (C) 2018-2020 Intel Corporation
-// SPDX-License-Identifier: Apache-2.0
-//
-
-#include <tuple>
-#include <vector>
-#include <string>
-
-#include <ie_core.hpp>
-#include "common_test_utils/test_assertions.hpp"
-#include "common_test_utils/common_utils.hpp"
-#include "functional_test_utils/plugin_cache.hpp"
-#include "functional_test_utils/layer_test_utils.hpp"
-#include "functional_test_utils/blob_utils.hpp"
-#include "ie_preprocess.hpp"
-#include "ngraph_functions/subgraph_builders.hpp"
-#include "behavior/set_preprocess.hpp"
-#include "common_test_utils/behavior_test_utils.hpp"
-
-using PreprocessBehTest = BehaviorTestsUtils::PreprocessBehTest;
-
-TEST_P(PreprocessBehTest, SetPreProcessToInputInfo) {
-    // Skip test according to plugin specific disabledTestPatterns() (if any)
-    SKIP_IF_CURRENT_TEST_IS_DISABLED()
-    // Create CNNNetwork from ngrpah::Function
-    InferenceEngine::CNNNetwork cnnNet(function);
-
-    auto &preProcess = cnnNet.getInputsInfo().begin()->second->getPreProcess();
-    preProcess.setResizeAlgorithm(InferenceEngine::ResizeAlgorithm::RESIZE_BILINEAR);
-
-    // Get Core from cache
-    auto ie = PluginCache::get().ie();
-    // Load CNNNetwork to target plugins
-    auto execNet = ie->LoadNetwork(cnnNet, targetDevice, configuration);
-    // Create InferRequest
-    auto req = execNet.CreateInferRequest();
-    {
-        InferenceEngine::ConstInputsDataMap inputsMap = execNet.GetInputsInfo();
-        const auto& name = inputsMap.begin()->second->name();
-        const InferenceEngine::PreProcessInfo *info = &req.GetPreProcess(name.c_str());
-        ASSERT_EQ(info->getResizeAlgorithm(), InferenceEngine::ResizeAlgorithm::RESIZE_BILINEAR);
-        ASSERT_PREPROCESS_INFO_EQ(preProcess, *info);
-    }
-    function.reset();
-    }
-
-TEST_P(PreprocessBehTest, SetPreProcessToInferRequest) {
-    // Skip test according to plugin specific disabledTestPatterns() (if any)
-    SKIP_IF_CURRENT_TEST_IS_DISABLED()
-    // Create CNNNetwork from ngrpah::Function
-    InferenceEngine::CNNNetwork cnnNet(function);
-
-    auto &preProcess = cnnNet.getInputsInfo().begin()->second->getPreProcess();
-    preProcess.setResizeAlgorithm(InferenceEngine::ResizeAlgorithm::RESIZE_BILINEAR);
-
-    // Get Core from cache
-    auto ie = PluginCache::get().ie();
-    // Load CNNNetwork to target plugins
-    auto execNet = ie->LoadNetwork(cnnNet, targetDevice, configuration);
-    // Create InferRequest
-    auto req = execNet.CreateInferRequest();
-    InferenceEngine::ConstInputsDataMap inputsMap = execNet.GetInputsInfo();
-    const auto& name = inputsMap.begin()->second->name();
-    auto inputBlob = FuncTestUtils::createAndFillBlob(
-            cnnNet.getInputsInfo().begin()->second->getTensorDesc());
-    req.SetBlob(cnnNet.getInputsInfo().begin()->first, inputBlob);
-    {
-        const InferenceEngine::PreProcessInfo *info = &req.GetPreProcess(name.c_str());
-        ASSERT_EQ(cnnNet.getInputsInfo().begin()->second->getPreProcess().getResizeAlgorithm(),
-                info->getResizeAlgorithm());
-    }
-    function.reset();
-    }
diff --git a/inference-engine/tests/ie_test_utils/common_test_utils/behavior_test_utils.hpp b/inference-engine/tests/ie_test_utils/common_test_utils/behavior_test_utils.hpp
index a4980504..76ecebdb 100644
--- a/inference-engine/tests/ie_test_utils/common_test_utils/behavior_test_utils.hpp
+++ b/inference-engine/tests/ie_test_utils/common_test_utils/behavior_test_utils.hpp
@@ -35,24 +35,21 @@ namespace BehaviorTestsUtils {
             std::map<std::string, std::string>  // Config
     > BehaviorParams;
 
-class BehaviorTestsCommon : public testing::WithParamInterface<BehaviorParams>,
-                            public CommonTestUtils::TestsCommon {
-public:
-     void SetUp() override;
-     void TearDown() override;
-protected:
-    BehaviorTestsCommon();
-
-    ~BehaviorTestsCommon() override;
-
-    std::string getTestCaseName(testing::TestParamInfo<BehaviorParams> obj);
-    std::shared_ptr<ngraph::Function> function;
-    InferenceEngine::Precision netPrecision;
-    std::string targetDevice;
-    std::map<std::string, std::string> configuration;
-};
+//class BehaviorTestsCommon : public testing::WithParamInterface<BehaviorParams>,
+//                            public CommonTestUtils::TestsCommon {
+//public:
+//     void SetUp() override;
+//     void TearDown() override;
+//protected:
+//    BehaviorTestsCommon();
+//
+//    ~BehaviorTestsCommon() override;
+//
+//
+//};
 
-class BehaviorTestsBasic : public BehaviorTestsCommon {
+class BehaviorTestsBasic : public testing::WithParamInterface<BehaviorParams>,
+                           public CommonTestUtils::TestsCommon {
 public:
     static std::string getTestCaseName(testing::TestParamInfo<BehaviorParams> obj) {
         InferenceEngine::Precision  netPrecision;
@@ -70,19 +67,21 @@ public:
         return result.str();
     }
 
-    void SetUp() {
+    void SetUp()  override {
         std::tie(netPrecision, targetDevice, configuration) = this->GetParam();
         function = ngraph::builder::subgraph::makeConvPoolRelu();
     }
 
-    void TearDown() {
+    void TearDown() override {
         if (targetDevice.find(CommonTestUtils::DEVICE_GPU) != std::string::npos) {
             PluginCache::get().reset();
         }
     }
-};
 
-
-using PreprocessBehTest = BehaviorTestsBasic;
+    std::shared_ptr<ngraph::Function> function;
+    InferenceEngine::Precision netPrecision;
+    std::string targetDevice;
+    std::map<std::string, std::string> configuration;
+};
 
 }  // namespace BehaviorTestsUtils
