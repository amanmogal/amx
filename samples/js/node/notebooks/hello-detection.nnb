{
    "cells": [
        {
            "language": "markdown",
            "source": [
                "# Hello Object Detection\n\nA very basic introduction to using object detection models with OpenVINOâ„¢.\n\nThe [horizontal-text-detection-0001](https://docs.openvino.ai/2023.0/omz_models_model_horizontal_text_detection_0001.html) model from [Open Model Zoo](https://github.com/openvinotoolkit/open_model_zoo/) is used. It detects horizontal text in images and returns a blob of data in the shape of `[100, 5]`. Each detected text box is stored in the `[x_min, y_min, x_max, y_max, conf]` format, where the\n`(x_min, y_min)` are the coordinates of the top left bounding box corner, `(x_max, y_max)` are the coordinates of the bottom right bounding box corner and `conf` is the confidence for the predicted class."
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Imports"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "const { addon: ov } = require('openvino-node');\nconst { display } = require('node-kernel');\n\nconst Image = require('../image');\nconst { transform, argMax, setShape } = require('../helpers.js');\n"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Load the Model"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "const modelXMLPath = '../../assets/models/horizontal-text-detection-0001.xml';\n\n// Initialize OpenVINO core and load the detection model\nconst core = new ov.Core();\nconst model = await core.readModel(modelXMLPath);\nconst compiledModel = await core.compileModel(model, 'AUTO');\nconst inputLayer = compiledModel.input(0);\nconst outputLayer = compiledModel.output('boxes');\n"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Load an Image"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "const imagePath = '../../assets/images/intel_rnb.jpg';\nconst img = await Image.load(imagePath);\nimg.display(display);\n\n// Resize the image to meet network input size\nconst [inputHeight, inputWidth] = inputLayer.shape.slice(2);\nconst resizedImg = img.resize(inputWidth, inputHeight);\n\n// Prepare input tensor\nconst inputImageTransformedData = transform(\n  resizedImg.rgb,\n  { width: inputWidth, height: inputHeight },\n  [0, 1, 2],\n);\nconst tensorData = new Float32Array(inputImageTransformedData);\nconst tensor = new ov.Tensor(ov.element.f32, inputLayer.shape, tensorData);\n"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Do Inference"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "const inferRequest = compiledModel.createInferRequest();\nconst result = await inferRequest.inferAsync([tensor]);\n"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Initialize helper functions\n"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "// Function to extract bounding boxes from the model output\nfunction extractBoundingBoxes(output) {\n  const { data: boxes } = output;\n  const foldingCoefficient = 5;\n  const numberOfBoxes = boxes.length / foldingCoefficient;\n\n  return setShape(boxes, [numberOfBoxes, foldingCoefficient]);\n}\n\n// Function to adjust bounding box coordinates by a given ratio\nfunction multiplyByRatio(ratioX, ratioY, box) {\n  const scaleShape = (shape, idx) => {\n    const position = idx % 2\n      ? Math.max(shape * ratioY, 10)\n      : shape * ratioX;\n\n    return Math.floor(position);\n  }\n\n  return box.map(scaleShape);\n}"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Visualize Results"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "// Calculate ratios\nconst [ratioX, ratioY] = [img.width / inputWidth, img.height / inputHeight];\nconst boundingBoxesArray = extractBoundingBoxes(result[outputLayer]);\n// Resize bounding boxes to the original image size\nconst boundingBoxesOriginalSizeArray = boundingBoxesArray.map(box =>\n  [...multiplyByRatio(ratioX, ratioY, box), box[4]]);\n\n// Takes original image and bounding boxes\n// and returns the image with bounding boxes drawn on it\nasync function putBoundingBoxesOnImage(img, boxes, threshold = 0.3) {\n  let finalImage = img;\n\n  for (const box of boxes) {\n    const conf = box[box.length - 1];\n\n    if (conf < threshold) continue;\n\n    const [xMin, yMin, xMax, yMax] = box;\n\n    finalImage = finalImage.drawRect(\n      xMin, yMin,\n      xMax - xMin, yMax - yMin,\n      { color: 'red', width: 3 },\n    );\n  }\n\n  return finalImage;\n}\n\n\nconst resultImg = await putBoundingBoxesOnImage(\n  img,\n  boundingBoxesOriginalSizeArray,\n);\nresultImg.display(display);\n"
            ],
            "outputs": []
        }
    ]
}