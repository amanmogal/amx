{
    "cells": [
        {
            "language": "markdown",
            "source": [
                "# Hello Image Segmentation\n\nA very basic introduction to using segmentation models with OpenVINOâ„¢.\nIn this tutorial, a pre-trained [road-segmentation-adas-0001](https://docs.openvino.ai/2023.0/omz_models_model_road_segmentation_adas_0001.html) model from the [Open Model Zoo](https://github.com/openvinotoolkit/open_model_zoo/) is used. ADAS stands for Advanced Driver Assistance Services. The model recognizes four classes: background, road, curb and mark.\n"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Imports"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "const { display } = require('node-kernel');\nconst { addon: ov } = require('openvino-node');\n\nconst Image = require('../image.js');\nconst {\n  transform,\n} = require('../helpers');\n"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Load the Model"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "const modelXMLPath = '../../assets/models/road-segmentation-adas-0001.xml';\n\nconst core = new ov.Core();\nconst model = await core.readModel(modelXMLPath);\nconst compiledModel = await core.compileModel(model, 'AUTO');\n\nconst inputLayer = compiledModel.input(0);\nconst outputLayer = compiledModel.output(0);\n"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Load an Image\n\nA sample image from the [Mapillary Vistas](https://www.mapillary.com/dataset/vistas) dataset is provided. "
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "const img = await Image.load('../../assets/images/empty_road_mapillary.jpg');\n\nimg.display(display);\n"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Do Inference"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "const [height, width] = inputLayer.shape.slice(2);\nconst resizedImg = img.resize(width, height);\n\n// Transform image data from NHWC to NCHW to match model input\n// as alternative you can use ov.preprocess.PrePostProcessor\n// see hello_reshape_ssd.js sample\nconst transformedImgData = transform(resizedImg.rgb, { width, height }, [0, 1, 2]);\nconst tensor = new ov.Tensor(\n  ov.element.f32,\n  inputLayer.shape,\n  new Float32Array(transformedImgData),\n);\n\nconst inferRequest = compiledModel.createInferRequest();\nconst outputs = await inferRequest.inferAsync([tensor]);\nconst output = outputs[outputLayer];\nconst outputData = output.data;\n"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Visualize data"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "const layers = { bg: [], c: [], h: [], w: [] };\nconst resultLayer = [];\nconst colormap = [\n  [68, 1, 84, 255],\n  [48, 103, 141, 255],\n  [53, 183, 120, 255],\n  [199, 216, 52, 255],\n];\nconst size = outputData.length/4;\n\nfor (let i = 0; i < size; i++) {\n  const valueAt = (i, number) => outputData[i + number*size];\n\n  const currentValues = {\n    bg: valueAt(i, 0),\n    c: valueAt(i, 1),\n    h: valueAt(i, 2),\n    w: valueAt(i, 3),\n  };\n  const values = Object.values(currentValues);\n  const maxIndex = values.indexOf(Math.max(...values));\n\n  resultLayer.push(maxIndex);\n}\n\nconst pixels = [];\nresultLayer.forEach(i => pixels.push(...colormap[i]));\n\nconst alpha = 0.6;\nconst [N, C, H, W] = output.getShape();\n\nconst segmentsImg = Image.fromArray(pixels, W, H);\nconst resizedSegments = segmentsImg.resize(img.width, img.height);\nconst mergedImg = Image.overlay(img, resizedSegments, alpha);\n\nmergedImg.display(display);\n"
            ],
            "outputs": []
        }
    ]
}