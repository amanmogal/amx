{
    "cells": [
        {
            "language": "markdown",
            "source": [
                "# Human Pose Estimation with OpenVINOâ„¢\n\nThis notebook demonstrates live pose estimation with OpenVINO, using the OpenPose human-pose-estimation-0001 model"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Imports"
            ],
            "outputs": []
        },
        {
            "language": "javascript",
            "source": [
                "const path = require('node:path');\nconst { display } = require('node-kernel');\nconst tf = require('@tensorflow/tfjs-node');\nconst { addon: ov } = require('openvino-node');\n\nconst { transform } = require('../helpers.js');\nconst Image = require('../image');\n"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Load the Model"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "const modelXMLPath = '../../assets/models/human-pose-estimation-0001.xml';\n\nconst core = new ov.Core();\nconst model = await core.readModel(modelXMLPath);\nconst compiledModel = await core.compileModel(model, 'AUTO', { PERFORMANCE_HINT: 'LATENCY' });\n\nconst inputLayer = compiledModel.inputs[0];\nconst outputLayers = compiledModel.outputs;\n\nconst [height, width] = inputLayer.shape.slice(2);\n\nconst heatmapsOutputKey = 'Mconv7_stage2_L2';\n\nconst THRESHOLD = 0.3;\nconst COLOR = 'rgb(0,255,0)';\n"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Load an Image"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "const imagePath = '../../assets/images/intel_rnb.jpg';\nconst img = await Image.load(imagePath);\nimg.display(display);\n\n// Resize the image to meet network input size\nconst [inputHeight, inputWidth] = inputLayer.shape.slice(2);\nconst resizedImg = img.resize(inputWidth, inputHeight);\n\n// Prepare input tensor\nconst inputImageTransformedData = transform(\n  resizedImg.rgb,\n  { width: inputWidth, height: inputHeight },\n  [0, 1, 2],\n);\nconst tensorData = new Float32Array(inputImageTransformedData);\nconst tensor = new ov.Tensor(ov.element.f32, inputLayer.shape, tensorData);\n"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Define postprocessing functions"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "// Utility function to get the coordinates of the maximum value in a tensor\nfunction getCoords(tensor) {\n  const { values, indices } = tf.topk(tensor.flatten(), 1);\n  const [maxVal] = values.dataSync();\n  const [maxIndex] = indices.dataSync();\n  const x = maxIndex % tensor.shape[1];\n  const y = Math.floor(maxIndex / tensor.shape[1]);\n\n  return { x, y, confidence: maxVal };\n}\n\n// Draw keypoints on the input image\nfunction drawKeypoints(image, keypoints) {\n  let modifiedImage = image;\n\n  keypoints.forEach(keypoint => {\n    if (keypoint.confidence < THRESHOLD) return;\n\n    modifiedImage = modifiedImage.drawCircle(\n      keypoint.x,\n      keypoint.y,\n      4,\n      { color: COLOR, width: 3 },\n    );\n  });\n\n  return modifiedImage;\n}\n\n// Draw skeleton (lines between keypoints) on the input image\nfunction drawSkeleton(image, keypoints) {\n  const skeleton = [\n    [1, 2], [1, 5], [2, 3], [3, 4], [5, 6], [6, 7], [1, 8], [8, 9], [9, 10],\n    [1, 11], [11, 12], [12, 13], [1, 0], [0, 14], [14, 16], [0, 15], [15, 17],\n  ];\n\n  let modifiedImage = image;\n  skeleton.forEach(([start, end]) => {\n    const startPoint = keypoints[start];\n    const endPoint = keypoints[end];\n\n    if (startPoint.confidence < THRESHOLD\n      || endPoint.confidence < THRESHOLD) return;\n\n    modifiedImage = modifiedImage.drawLine(\n      startPoint.x,\n      startPoint.y,\n      endPoint.x,\n      endPoint.y,\n      { color: COLOR, width: 3 },\n    );\n  });\n\n  return modifiedImage;\n}\n\nfunction toTFTensor(ovTensor) {\n  return tf.tensor(ovTensor.data, ovTensor.getShape());\n}"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Do Inference"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "const inferRequest = compiledModel.createInferRequest();\nconst outputs = await inferRequest.inferAsync([tensor]);\n\nconst heatmaps = outputs[heatmapsOutputKey];"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Process result"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "try {\n  const [N, C, heatmapHeight, heatmapWidth] = heatmaps.getShape();\n\n  // Define constants\n  const numKeypoints = 18;\n\n  // Extract keypoints from heatmaps\n  let keypoints = [];\n  const heatmapsTFTensors = toTFTensor(heatmaps);\n  const xCoef = img.width / heatmapWidth;\n  const yCoef = img.height / heatmapHeight;\n\n  for (let i = 0; i < numKeypoints; i++) {\n    const heatmap = heatmapsTFTensors.slice(\n      [0, i, 0, 0],\n      [1, 1, heatmapHeight, heatmapWidth]).squeeze();\n\n    const { x, y, confidence } = getCoords(heatmap);\n\n    keypoints.push({\n      x: x * xCoef,\n      y: y * yCoef,\n      confidence,\n    });\n  }\n\n  let imgWithKeypoints = drawKeypoints(img, keypoints);\n  imgWithKeypoints = drawSkeleton(imgWithKeypoints, keypoints);\n\n  imgWithKeypoints.display(display);\n} catch(e) {\n  console.log(e);\n}"
            ],
            "outputs": []
        }
    ]
}