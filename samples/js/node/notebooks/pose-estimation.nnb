{
    "cells": [
        {
            "language": "markdown",
            "source": [
                "# Human Pose Estimation with OpenVINOâ„¢\n\nThis notebook demonstrates live pose estimation with OpenVINO, using the OpenPose human-pose-estimation-0001 model"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Imports"
            ],
            "outputs": []
        },
        {
            "language": "javascript",
            "source": [
                "const { cv } = require('opencv-wasm');\nconst { display } = require('node-kernel');\nconst tf = require('@tensorflow/tfjs-node');\nconst { getImageData, displayImage, downloadFile } = require('../helpers.js');\n\nconst OpenPoseDecoder = require('../openpose_decoder.js');\nconst utils = require('../utils.js');\nconst { addon: ov } = require('openvino-node');\n"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Download the Model"
            ],
            "outputs": []
        },
        {
            "language": "javascript",
            "source": [
                "const baseArtifactsDir = '../../assets/models';\n\nconst modelName = 'human-pose-estimation-0001';\nconst modelXMLName = `${modelName}.xml`;\nconst modelBINName = `${modelName}.bin`;\n\nconst modelXMLPath = baseArtifactsDir + '/' + modelXMLName;\n\nconst baseURL = `https://storage.openvinotoolkit.org/repositories/open_model_zoo/2022.1/models_bin/3/${modelName}/FP16-INT8/`;\n\nawait downloadFile(baseURL + modelXMLName, modelXMLName, baseArtifactsDir);\nawait downloadFile(baseURL + modelBINName, modelBINName, baseArtifactsDir);\n\nconst imgUrl = 'https://storage.openvinotoolkit.org/repositories/openvino_notebooks/data/data/image/intel_rnb.jpg';\n\nawait downloadFile(imgUrl, 'intel_rnb.jpg', '../../assets/images');\n"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "const core = new ov.Core();\nconst model = await core.readModel(modelXMLPath);\nconst compiledModel = await core.compileModel(model, 'CPU', { PERFORMANCE_HINT: 'LATENCY' });\n\nconst inputLayer = compiledModel.inputs[0];\nconst outputLayers = compiledModel.outputs;\n\nconst [height, width] = inputLayer.shape.slice(2);\n\nconst pafsOutputKey = 'Mconv7_stage2_L1';\nconst heatmapsOutputKey = 'Mconv7_stage2_L2';\n"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Processing"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "try {\n  const decoder = new OpenPoseDecoder();\n\n  /**\n   * Processes the results to extract poses and scores from the heatmaps and PAFs.\n   * @param {tf.Tensor} img - The input image tensor.\n   * @param {tf.Tensor} pafs - The PAFs tensor.\n   * @param {tf.Tensor} heatmaps - The heatmaps tensor.\n   * @param {Object} compiledModel - The compiled model (for output shape).\n   * @returns {Array} - An array containing poses and scores.\n   */\n  async function processResults(img, pafsTensor, heatmapsTensor, compiledModel) {\n    const pafs = utils.toTFTensor(pafsTensor);\n    const heatmaps = utils.toTFTensor(heatmapsTensor);\n\n    // Apply 2D pooling to the heatmaps\n    const pooledHeatmaps = tf.tidy(() => {\n      const pooledHeatmapsArray = heatmaps.arraySync().map(batch => {\n        // console.log(batch);\n\n        return batch.map(h => {\n          console.log('=== h');\n          // console.log(h.length);\n          // console.log(h[0].length);\n          // console.log(tf.tensor2d(h));\n\n          return utils.pool2d(tf.tensor2d(h), 3, 1, 1, 'max');\n        });\n      });\n      console.log(pooledHeatmapsArray)\n\n      // return tf.tensor(pooledHeatmapsArray);\n    });\n\n    return;\n\n    // Apply Non-Maximum Suppression\n    const nmsHeatmaps = utils.heatmapNms(heatmaps, pooledHeatmaps);\n\n    // Decode poses using the OpenPoseDecoder\n    const [poses, scores] = await decoder.call(heatmaps, nmsHeatmaps, pafs);\n\n    // Get the output shape of the model\n    const outputShape = compiledModel.output(0).shape;\n\n    // Calculate the output scale based on image and model output shape\n    const outputScale = [\n      img.shape[1] / outputShape[3],\n      img.shape[0] / outputShape[2]\n    ];\n\n    // Multiply coordinates by scaling factor\n    poses.forEach(pose => {\n      pose.forEach(point => {\n        point[0] *= outputScale[0];\n        point[1] *= outputScale[1];\n      });\n    });\n\n    return [poses, scores];\n  }\n\n\n  async function executePoseEstimation(imagePath) {\n    const imgData = await getImageData(imagePath);\n\n    const originalImage = cv.matFromImageData(imgData);\n    const { cols: originalWidth, rows: originalHeight } = originalImage;\n\n    const image = new cv.Mat();\n    cv.cvtColor(originalImage, image, cv.COLOR_RGBA2RGB);\n    cv.cvtColor(image, image, cv.COLOR_BGR2RGB);\n\n    // Resize the image and change dims to fit neural network input.\n    // (see https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel/human-pose-estimation-0001)\n    console.log(width, height);\n    cv.resize(image, image, new cv.Size(width, height), cv.INTER_AREA);\n\n    const inputImage = image;\n    // console.log({ inputImage: inputImage.data });\n\n    const tensorData = new Float32Array(inputImage.data);\n    const tensor = new ov.Tensor(ov.element.f32, inputLayer.shape, tensorData);\n\n    const inferRequest = compiledModel.createInferRequest();\n    inferRequest.setInputTensor(tensor);\n    const outputs = inferRequest.infer();\n\n    const pafs = outputs[pafsOutputKey];\n    const heatmaps = outputs[heatmapsOutputKey];\n\n    // const [poses, scores] =\n    await processResults(image, pafs, heatmaps, compiledModel);\n\n    // console.log(poses, scores);\n  }\n\n  const imagePath = '../../assets/images/intel_rnb.jpg';\n\n  executePoseEstimation(imagePath);\n\n} catch (e) {\n  console.log(e);\n}\n"
            ],
            "outputs": []
        }
    ]
}